{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A program that reads and processes images for a Support Vector Machine (SVM) to classify as images as good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(paths): \n",
    "    \"\"\"\n",
    "    Reads in all images and returns list of picture id numbers based on the image name\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    paths : string\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    images and list of id numbers\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Get list of images\n",
    "    images = (glob(paths + '*.jpg'))\n",
    "    # Read images from list\n",
    "    data = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2GRAY) for file in images]\n",
    "    data = np.array(data)\n",
    "    data = data.reshape((len(data),-1))\n",
    "    \n",
    "    print(data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_layers(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Builds layers of Support Vector Machine\n",
    "    Fits model to the data\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    X_train = array\n",
    "    X_test = array\n",
    "    y_train = data frame or array\n",
    "    y_test = data frame or array\n",
    "       \n",
    "    Returns\n",
    "    ------------\n",
    "    model metrics evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    model = svm.SVC(gamma=0.001)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    return model,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_models(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Fits supervised models to data and returns metrics\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    model = supervised learning model\n",
    "    X_train = array\n",
    "    y_train = data frame or array\n",
    "       \n",
    "    Returns\n",
    "    ------------\n",
    "    model metrics evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    probabilities = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "    return model, probabilities, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/micha/ea-applications/data/test-images.csv')\n",
    "\n",
    "paths = '/Users/micha/ea-applications/data/training-test-images/Thermal'\n",
    "\n",
    "train_images = read_images(paths)\n",
    "\n",
    "y = np.array(df_train['Label'])\n",
    "\n",
    "y = df_train['Label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, y, random_state=42, test_size=0.2)\n",
    "\n",
    "print(df_train.head())\n",
    "print(X_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run svm model\n",
    "svm_model, metrics = svm_layers(X_train, y_train, X_test, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression model\n",
    "model = linear_model.LogisticRegression()\n",
    "model_logistic, probabilities, y_pred = supervised_models(model, X_train, y_train)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random forest classifier\n",
    "model = RandomForestClassifier()\n",
    "model_logistic, probabilities, y_pred = supervised_models(model, X_train, y_train)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient boosting classifier\n",
    "model = GradientBoostingClassifier()\n",
    "model_boosting, probabilities, y_pred = supervised_models(model, X_train, y_train)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
